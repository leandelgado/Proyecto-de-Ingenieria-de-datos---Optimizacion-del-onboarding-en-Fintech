# Proyecto de Ingenier√≠a de Datos: Optimizaci√≥n del Onboarding en Fintech

Este repositorio contiene la implementaci√≥n de un pipeline ETL (Extracci√≥n, Transformaci√≥n y Carga) para un proyecto de Ingenier√≠a de Datos. El objetivo principal es mejorar el *engagement* de los usuarios con una aplicaci√≥n Fintech, centr√°ndose en la reducci√≥n de la p√©rdida de usuarios durante la etapa de *onboarding* inicial. La soluci√≥n aborda un problema de negocio real mediante el procesamiento y an√°lisis de datos a gran escala, utilizando una arquitectura Big Data distribuida.

## üìù Descripci√≥n del Problema

Una Fintech con operaciones en Latinoam√©rica busca incrementar el *engagement* de sus usuarios para reducir la p√©rdida de usuarios registrados, especialmente durante los primeros d√≠as de uso de la aplicaci√≥n. Un an√°lisis previo sugiri√≥ que esta p√©rdida podr√≠a estar relacionada con la complejidad de la aplicaci√≥n y la alta carga cognitiva para los usuarios nuevos.

Para abordar esto, se propuso implementar una etapa de *onboarding* de 30 d√≠as de duraci√≥n, guiando a los nuevos usuarios en la creaci√≥n de productos bancarios y reduciendo la carga cognitiva de la p√°gina de inicio durante este per√≠odo. Para medir la efectividad de esta propuesta, se dise√±√≥ un experimento de tipo A/B Testing, observando m√©tricas clave durante seis meses en usuarios de Brasil.

## üéØ Objetivos del Proyecto

* Desarrollar un proceso ETL robusto utilizando Apache Spark y Apache Cassandra.
* Implementar una arquitectura Big Data distribuida.
* Realizar una exhaustiva etapa de pre-procesamiento para asegurar la consistencia y calidad de los datos.
* Preparar los datos en una etapa de transformaci√≥n para el an√°lisis del desempe√±o de la etapa de *onboarding* en el grupo de tratamiento.
* Calcular m√©tricas de negocio clave para evaluar el √©xito de la estrategia de *onboarding*.

## üèóÔ∏è Arquitectura Utilizada

Para este trabajo, se implement√≥ una arquitectura Big Data distribuida, aprovechando las siguientes tecnolog√≠as:

* **Apache Cassandra / DataStax**: Base de datos NoSQL orientada a columnas, escalable y distribuida. Su rol en la arquitectura es el almacenamiento persistente de los datos. DataStax, como plataforma empresarial basada en Cassandra, proporciona herramientas adicionales para gesti√≥n, seguridad y an√°lisis en tiempo real.
* **Apache Spark (PySpark)**: Motor de procesamiento distribuido. Se utiliz√≥ PySpark (la interfaz Python de Spark) para la transformaci√≥n, an√°lisis y limpieza de datos. Es fundamental para tareas de ETL (extracci√≥n, transformaci√≥n y carga), procesamiento por lotes, limpieza de datos, agregaciones y uniones.

## üíª Tecnolog√≠as y Librer√≠as Utilizadas

* **Apache Cassandra**: Base de datos NoSQL distribuida [cite: 5][cite_start], utilizada como fuente y destino de los datos.
* **DataStax**: Base de datos en la nube  (Astra) para el almacenamiento de datos limpios en la "zona Universal".
* **Apache Spark**: Motor de procesamiento distribuido.
* **PySpark**: Interfaz Python para Apache Spark.
* **Pandas**: Librer√≠a Python utilizada.
* **NumPy**: Librer√≠a Python utilizada.
* **AstraPy**: Librer√≠a Python utilizada.
* **DateTime**: Librer√≠a Python utilizada.

## üìä Datasets Utilizados

Se proporcionaron extractos hist√≥ricos de los siguientes datasets:

* `dim_users`: Contiene informaci√≥n de usuarios en *onboarding* para una fecha determinada, incluyendo `user_id` (identificador √∫nico de usuario con prefijo "MLB" para usuarios de Brasil) y `rubro` (un identificador de rubro de negocio para usuarios del segmento *seller*).
* `fact_users_transactions`: Contiene todas las transacciones de los usuarios realizadas durante un per√≠odo determinado , incluyendo `transaction_dt` (fecha de una transacci√≥n) , `type` (identificador de tipo de transacci√≥n: 1-7 para pago, 8 y 9 para cobro), y `segment` (1 para *individuals*, 2 para *seller*).
* `fact_users_onboarding`: Contiene la informaci√≥n del usuario de *onboarding* que permite calcular las m√©tricas de negocio para un per√≠odo determinado, incluyendo `first_login_dt` (fecha hist√≥rica del primer inicio de sesi√≥n), `habito` (1 para presencia del atributo, 0 en caso contrario), `habito_dt` (fecha en que realiza el evento de h√°bito), `activacion` (1 para presencia del atributo, 0 en caso contrario), `activacion_dt` (fecha en que realiza el evento de activaci√≥n), `setup` (1 para presencia del atributo, 0 en caso contrario), `setup_dt` (fecha en que realiza el evento de setup), y `return` (1 si el usuario retorn√≥ posteriormente al *first login*).

## üßπ Acciones de Pre-procesamiento y Transformaci√≥n

Se realiz√≥ una limpieza y transformaci√≥n exhaustiva de los datos, respetando siempre criterios basados en la l√≥gica de negocio. Este proceso asegur√≥ la consistencia de los datos, abordando valores perdidos e inconsistencias, para dejar las tablas `users`, `onboarding` y `transactions` listas para el an√°lisis. Los datos limpios fueron cargados en Astra, en la zona Universal.

## üìà Hallazgos y Resultados

Se utilizaron consultas SQL con PySpark sobre los datos limpios en la "zona Universal", permitiendo calcular m√©tricas clave que luego alimentaron la "zona Smart".

Los resultados obtenidos fueron los siguientes:

| M√©trica                 | Valor    |
| :---------------------- | :------- |
| **Drop Rate** | 29.00 %  |
| **Activation Rate** | 11.80 %  |
| **Setup Rate** | 44.60 %  |
| **Habito Individuals** | 4758     |
| **Habito Sellers** | 505      |

### Definiciones Clave:

* **Drop Rate**: Porcentaje de usuarios que no volvieron a usar la aplicaci√≥n despu√©s del registro.
* **Activation Rate**: Porcentaje de usuarios en *onboarding* que realizaron al menos una primera acci√≥n transaccional. Para este proyecto, se consideraron usuarios que realizaron al menos 5 transacciones.
* **Setup Rate**: Porcentaje de usuarios que realizaron al menos una acci√≥n de *setup* (por ejemplo, activar llave PIX, cargar tarjeta).
* **H√°bito Individuals**: Usuarios que realizan 5 transacciones en 5 d√≠as diferentes, durante el per√≠odo de *onboarding* (fijado en 30 d√≠as).
* **H√°bito Sellers**: Usuarios que realizan 5 transacciones de cobro (sin importar los d√≠as), durante el per√≠odo de *onboarding* (fijado en 30 d√≠as).

## üìå Conclusi√≥n

Se ha implementado un proceso ETL integral y una arquitectura Big Data distribuida utilizando Apache Spark y Apache Cassandra. La limpieza y transformaci√≥n exhaustiva de los datos, guiadas por la l√≥gica de negocio, han permitido obtener un conjunto de datos consistente y listo para el an√°lisis. Las m√©tricas calculadas proporcionan una base s√≥lida para evaluar el desempe√±o de la etapa de *onboarding* y tomar decisiones informadas para mejorar el *engagement* de los usuarios.

---
 
